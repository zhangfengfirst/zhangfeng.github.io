##### 概率论与数理统计之概念

###### 第七章

- 统计推断
  - 参数估计
    - 点估计
      - 矩估计法
      - 最大似然估计法
      - 贝叶斯法
    - 区间估计
  - 假设检验



1. 统计推断

   统计推断为我们提供了从样本数据中得出有关总体结论的方法，通常分为两大类：==参数估计==与==假设检验==。

2. 参数估计

   参数指的是总体分布函数 $F(x,\theta)$ 中所含的未知参数 $\theta$ 。在统计研究中，参数的含义更广泛一些，用来刻画总体某方面性质的量统称为参数。在实际应用中，==参数估计通常有两种方案：点估计和区间估计==。

3. 点估计

   点估计就是用一个具体的数值去估计一个未知参数。估计某个城市居民某年的人均消费为10000元是一个点估计。==点估计的三种方法：矩估计法、最大似然估计法和贝叶斯法==。

   设总体$X$的分布函数已知为 $F(x,\theta)$ ， $\theta$ 是待估参数，$X_1,X_2,...,X_n$ 是 $X$ 的一个样本（$n$ 个样本点），$x_1,x_2,...,x_n$ 是相应的样本值。点估计问题就是要构造适当的一个统计量 $\hat{\theta}(X_1,X_2,...,X_n)$ ，用来估计未知参数 $\theta$ ，我们称 $\hat{\theta}(X_1,X_2,...,X_n)$ 为 $\theta$ 的==估计量==。如果把其中的样本用样本观测值 $x_1,x_2,...,x_n$ 代替，则称 $\hat{\theta}(x_1,x_2,...,x_n)$ 为 $\theta$ 的一个==估计值==。一般情况下，统称估计量和估计值为估计，并都简记为 $\theta$ 。

   统计学定义一个==统计量==为一个总体参数的点估计量。

4. 区间估计

   区间估计就是把未知参数估计在两个界限之间。估计某个城市居民某年的人均消费在8000元到12000元之间是一个区间估计。

5. 矩估计量

   随机变量（或统计量）的期望（Exception）定义为其==1阶原点矩==。

   随机变量的方差（Variance）定义为其==2阶中心矩==。

   随机变量的偏态（Skewness，均值的歪斜分布情况）定义为其==3阶中心矩==。

   随机变量的峰态（Kurtosis，峰值的分布情况）定义为其==4阶中心矩==。

   我的理解：用样本的矩（期望、方差等）估计总体的期望，方差。

   用样本矩作为相应的总体矩的估计量，而以样本矩的连续函数作为相应的总体矩的连续函数的估计量，这种估计方法称为矩估计方法。

6. 最大似然估计量

   极大似然估计法的基本思想是：设某事件A发生的概率依赖于未知参数 $\theta$，如果观察到A已经发生，那么就取 $\theta$ 估计值使得事件A发生的概率为最大（取使得事件A发生概率最大的 $\theta$ 估计值）。

   若总体 $X$ 属于==离散型==，

   其==分布律== $P\{X=x\}=p(x;\theta)$，$\theta\in\Theta$ 的形式为已知，$\theta$ 为待估参数，$\Theta$ 是 $\theta$ 的可能取值范围；

   设 $X_1,X_2,...,X_n$ 是来自 $X$ 的样本，则 $X_1,X_2,...,X_n$ 的==联合分布律==为 $\prod_{i=1}^n p(x_i;\theta)$；

   设 $x_1,x_2,...,x_n$ 是相应于样本 $X_1,X_2,...,X_n$ 的一个样本值，易知样本 $X_1,X_2,...,X_n$ 取到观察值 $x_1,x_2,...,x_n$ 的概率，亦即==事件== $\{X_1=x_1,X_2=x_2,...,X_n=x_n\}$ ==发生的概率==为
   $$
   L(\theta)=L(x_1,x_2,...,x_n;\theta)=\prod_{i=1}^np(x_i;\theta),\theta\in\Theta.
   $$
   这一概率随 $\theta$ 的取值而变化，它是 $\theta$ 的函数，$L(\theta)$ 称为==样本的似然函数==。（这里 $x_1,x_2,...,x_n$ 都是已知的样本值，他们都是常数）。

   由费希尔引进的==最大似然估计法==，就是固定样本观察值 $x_1,x_2,...,x_n$ 在 $\theta$ 取值的可能范围 $\Theta$ 内挑选使似然函数 $L(x_1,x_2,...,x_n;\theta)$ 达到最大的参数值 $\hat\theta$，作为参数 $\theta$ 的估计值。即取 $\hat\theta$ 使
   $$
   L(x_1,x_2,...,x_n;\hat\theta)=\max_{\theta\in\Theta}L(x_1,x_2,...,x_n;\theta).
   $$
   这样得到的 $\hat\theta$ 与样本值 $x_1,x_2,...,x_n$ 有关，常记为 $\hat\theta(x_1,x_2,...,x_n)$，称为参数 $\theta$ 的==最大似然估计值==，而相应的统计量 $\hat\theta(X_1,X_2,...,X_n)$ 称为参数 $\theta$ 的==最大似然估计量==。

   若总体 $X$ 属==连续型==，

   其==概率密度== $f(x;\theta),\theta\in\Theta$ 的形式已知，$\theta$ 为待估参数，$\Theta$ 是 $\theta$ 的可能取值范围。

   设 $X_1,X_2,...,X_n$ 是来自 $X$ 的样本，则 $X_1,X_2,...,X_n$ 的==联合密度==为 $\prod_{i=1}^nf(x_i;\theta)$。

   设 $x_1,x_2,...,x_n$ 是相应于样本 $X_1,X_2,...,X_n$ d的一个样本值，则随机点 $(X_1,X_2,...,X_n)$ 落在点 $(x_1,x_2,...,x_n)$ 的邻域（边长分别为 $dx_1,dx_2,...,dx_n$ 的 $n$ 维立方体 ）内的==概率==近似地为 
   $$
   \prod_{i=1}^nf(x_i;\theta)dx_i
   $$
   其值随 $\theta$ 的取值而变化，同离散型情况一样，我们取 $\theta$ 的估计值 $\hat\theta$ 使以上概率取最大值，但因子 $\prod_{i=1}^ndx_i$ 不随 $\theta$ 而变，故只需考虑函数
   $$
   L(\theta)=L(x_1,x_2,...,x_n;\theta)=\prod_{i=1}^nf(x_i;\theta)
   $$
   的最大值，这里 $L(\theta)$ 称为样本的==似然函数==。

   若
   $$
   L(x_1,x_2,...,x_n;\hat\theta)=\max_{\theta\in\Theta}L(x_1,x_2,...,x_n;\theta)
   $$
   ，则称 $\hat\theta(x_1,x_2,...,x_n)$ 为 $\theta$ 的==最大似然估计值==，称 $\hat\theta(X_1,X_2,...,X_n)$ 为 $\theta$ 的==最大似然估计量==。

   这样，确定最大似然估计量的问题就归结为微分学中的求最大值的问题了。

    

7. 估计量的评选标准

8. 置信区间

9. p值

10. 参数 $\theta$ 的置信水平为 $1- \alpha$ 的置信区间

11. 参数 $\theta$ 的单侧置信上限和单侧置信下限

12. 两个正态总体均值、方差的置信区间、单侧置信上限与单侧置信下限

13. 两个正态总体均值差、方差比的置信区间、单侧置信上限与单侧置信下限





